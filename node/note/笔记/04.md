## buffer

```js
{ Buffer:
   { [Function: Buffer]
     poolSize: 8192,
     isBuffer: [Function: isBuffer],
     compare: [Function: compare],
     isEncoding: [Function],
     concat: [Function],
     byteLength: [Function: byteLength] },
     SlowBuffer: [Function: SlowBuffer],
     INSPECT_MAX_BYTES: 50,
     kMaxLength: 2147483647 
}
```

在一些 `TCP` 数据流或者在操作一些文件数据流的时候，字节流的处理方法还是必须的

`Node.js` 中便出现了处理的策略方法，提供了与 `String` 类似对等的全局构造函数`Buffer`（与其说与 `String` 对等，还不如说与 `Array` 类似但是有些不同方面还是需要注意），`Buffer` 则 `node` 中储存二进制数据的中介者


## 创建 Buffer 实例

```js
new Buffer( size )               // 和数组类似，给定所需要创建 Buffer 对象的大小
new Buffer( array )              // 给定二进制数据的一个数组形式排列
new Buffer( str, [ encoding ] )  // 给与某一特定数据类型数据，以及其编码类型（默认均为 utf8）
```

## 一些操作 Buffer 实例的方法

`Buffer` 的形式非常类似于一个整数数组，与字符串还是有一定的区别的

```js
> var buf = new Buffer('hello world')
undefined

> buf.length
11

> buf.write('hi node')
7

> buf.toString()
'hi nodeorld'
```


在将创建的 `Buffer` 截取一段之后，对返回的 `Buffer` 段进行修改，还是会影响原 `Buffer`，两者仍是关联的

这类似于一个储存一个个对象的数组，`Buffer` 这个类数组中每一个元素非原始值，而是引用值

```js
> var buf = new Buffer('hello world')
undefined

> buf.length
11

> buf.write('hi node')
7

> buf.toString()
'hi nodeorld'

> buf.length
11

> buf.write(' nodenodenodenode', 2, 16)
9

> buf.toString()
'hi nodenode'
```

## 编码格式

```js
> var buf = new Buffer('hello world')
undefined

> var str = buf.toString('base64')
undefined

> str
'aGVsbG8gd29ybGQ='

> var buf = new Buffer('aGVsbG8gd29ybGQ=','base64')
undefined

> var str = buf.toString()
undefined

> str
'hello world'

> var buf = new Buffer('aGVsbG8gd29ybGQ=','base64')
undefined

> var str = buf.toString('hex')
undefined

> str
'68656c6c6f20776f726c64'

> var buf = new Buffer('68656c6c6f20776f726c64','hex')
undefined

> var str = buf.toString('utf8')
undefined

> str
'hello world'
```

只要设置正确的编码，那么创建的 `buffer` 对象所缓存的数据是一样的，都可以通过正确的转换还原回来，只不过编码格式有很多种，但是 `node` 支持的只有一部分


#### Buffer.copy(targetBuffer, [targetStart], [sourceStart], [sourceEnd])

相对来说并没有直接的直接拷贝副本的方法，只能新建一个长度相等的 `Buffer`，然后在原 `Buffer` 上调用 `copy` 方法，参数中还可以设置 `copy` 的启事与结束位置等，更多 `buffer` 相关内容可以查阅 [http://nodejs.org/api/buffer.html](http://nodejs.org/api/buffer.html)，一个实例，`copy` 图片，转换成 `base64` 格式

```js
var fs = require('fs')

fs.readFile('demo.png', function (err, origin_buffer) {
  console.log(Buffer.isBuffer(origin_buffer))
  fs.writeFile('demo_buffer.png', origin_buffer, function (err) {
    if (err) console.log(err)
  })

})

// 可以通过 new Buffer()
// var base64Image = new Buffer(origin_buffer).toString('base64')
// 也可以直接拿到，不需要构建一个新的 Buffer
var base64Image = origin_buffer.toString('base64')
console.log(base64Image)

var decodedImage = new Buffer(base64Image, 'base64')
console.log(Buffer.compare(origin_buffer, decodedImage))

fs.writeFile('demo_decoded.png', decodedImage, function (err) {
  if (err) console.log(err)
})
```









## Stream

一个简单的利用流读取文件的例子

```js
var fs = require('fs')
var source = fs.readFileSync('demo.png')

fs.writeFileSync('stream_demo.png', source)
```

以上这种方式是把文件内容全部读入内存，然后再写入文件，对于小型的文本文件，这没有多大问题，理想的方法应该是读一部分，写一部分，不管文件有多大，只要时间允许，总会处理完成，这里就需要用到流的概念，`Stream` 在 `Node.js` 中是 `EventEmitter` 的实现，并且有多种实现形式，例如

* `http responses request`
* `fs read write streams`
* `zlib streams`
* `tcp sockets`
* `child process stdout and stderr`

所有的流都是 `EventEmitter` 的实例，即 `stream` 是基于事件机制工作的，也就意味着，在流对象上具有异步的特征，可以监听事件，可以触发事件，流在各个阶段的变化都能被我们时时监听到

```js
var fs = require('fs')
var readStream = fs.createReadStream('stream_copy_demo.png')

readStream
  .on('data', function (chunk) {
    console.log('data emits')
    console.log(Buffer.isBuffer(chunk))
    console.log(chunk.toString('utf8'))
  })
  .on('readable', function () {
    console.log('data readable')
  })
  .on('end', function () {
    console.log('data ends')
  })
  .on('close', function () {
    console.log('data close')
  })
  .on('error', function (e) {
    console.log('data read error' + e)
  })
```

添加一个值来记录我们的调用次数

```js
var fs = require('fs')
var readStream = fs.createReadStream('demo.mp4')
var n = 0

readStream
  .on('data', function (chunk) {
    n++
    console.log('data emits')
    console.log(Buffer.isBuffer(chunk))
    // console.log(chunk.toString('utf8'))

    readStream.pause()
    console.log('data pause')
    setTimeout(function () {
      console.log('data pause end')
      readStream.resume()
    }, 5000)
  })
  .on('readable', function () {
    console.log('data readable')
  })
  .on('end', function () {
    console.log(n)
    console.log('data ends')
  })
  .on('close', function () {
    console.log('data close')
  })
  .on('error', function (e) {
    console.log('data read error' + e)
  })
```

以上就是借助于事件，来进行一些比较灵活的控制，现在，就可以利用事件来重构开头的实例

```js
var fs = require('fs')
var readStream = fs.cerateReadStream('demo.mp4')
var writeStream = fs.cerateWriteStream('demo_stream.mp4')

readStream.on('data', function (chunk) {
  writeStream.write(chunk)
})

readStream.on('end', function () {
  writeStream.end()
})
```

重构完成，但是有一点问题，那就是说如果读的快，写的慢，因为磁盘的 `I/O` 速度并不是恒定的，那么这个时候，数据流的缓存可能会被'爆仓'，所以，我们可以加个判断

```js
var fs = require('fs')
var readStream = fs.cerateReadStream('demo.mp4')
var writeStream = fs.cerateWriteStream('demo_stream.mp4')

readStream.on('data', function (chunk) {
  if (writeStream.write(chunk) === false) {
    console.log('still cached')
    readStream.pause()
  }
})

readStream.on('end', function () {
  writeStream.end()
})

writeStream.on('drain', function () {
  console.log('data drains')

  readStream.resume()
})
```

## Stream 种类

* `Readable streams`，可读流，用来提供数据，外部来源的数据会被存储到内部的Buffer上缓存起来，当流处于流动模式的时候，数据从底层系统中读出，会提供给上层的应用数据
* `Writable streams`，可写流，用来消费数据，从可读流里面获取数据以后，对得到的Buffer数据进行处理
* `Duplex streams`，也叫双通流，实现了 `Readable` 和 `Writable` 两个接口，如下所示的 `a` 就是一个 `duplex stream`，比如 `a.pipe(b).pipe(a)`
* `Transform streams`，转换流，它也是双通的，也实现了 `Readable` 和 `Writable` 两个接口，只不过它并不保存数据，只负责处理流经它的流，就像是流的中间部分

无论哪一种流，都会使用 `pipe()` 的方法来实现 输入/输出，`pipe` 的两边都是流，只不过左边是可读的，右边的则是目标流，左边的数据经过 `pipe` 输送给右边的目标流，目标流经过处理后可以继续往下不断的 `pipe`，即形成了一个 `pipe` 链条，串联起来，看下面一个实例

```js
var http = require('http')
var fs = require('fs')

http
  .createServer(function (req, res) {
    fs.readFile('./demo.png', function (err, data) {
      if (err) {
        res.end('file not exist!')
      } else {
        res.writeHeader(200, { 'Content-Type': 'text/html' })
        res.end(data)
      }
    })
  })
  .listen(8888)
``` 

使用 `pipe`，我们就可以更简洁的实现这套逻辑

```js
var http = require('http')
var fs = require('fs')
var request = require('request')

http
  .createServer(function (req, res) {
    // fs.readFile('./demo.png', function(err, data){
    //     if(err){
    //         res.end('file not exist!')
    //     } else {
    //         res.writeHeader(200, {'Content-Type':'text/html'})
    //         res.end(data)
    //     }
    // })

    // 本地图片
    fs.createReadStream('./demo.png').pipe(data)

    // 加载远程图片
    request('http://www.baidu.com/....abc.png').pipe(res)
  })
  .listen(8888)
```

`pipe` 方法会帮我们自动监听 `data` 和 `end` 事件，图片文件的数据会源源不断的发送给客户端，除此之外，`pipe` 还可以自动控制后端压力，这样在客户端连接缓慢的时候，`node` 可以将尽可能少的缓存放到内存中，通过对内存空间的调度，就可以自动控制流，从而避免目标被快速读取的可读流所淹没

并且，数据在 `pipe` 的时候，只有 `pipe` 链末端的目标流真正需要数据的时候，数据才会从源头被取出来，利用 `pipe` 重构之前的例子

```js
var fs = require('fs')

fs.createReadStream('demo.mp4').pipe(fs.createWriteStream('pipe_demo.mp4'))
```

总结以上就是

> 可读流，是负责读取外部的数据，并把数据缓存到内部的 `Buffer` 数组
> 
> 可写流负责消费数据，从可读流里面获取数据，然后对获取到的 `chunk` 数据块进行处理，具体怎样处理，取决于可写流内部的 `read` 方法怎么样实现



```js
var Readable = require('stream').Readable
var Writable = require('stream').Writable

var readStream = new Readable()
var writStream = new Writable()

readStream.push('a')
readStream.push('b')
readStream.push('c \n')

// 告诉可读流数据已经读取完毕
readStream.push(null)

writStream._write = function(chunk, encode, fn){
  console.log(chunk.toString())
  fn()
}

readStream.pipr(writStream)
```

最后用一个实例来加深对 `pipe` 的理解，实现一个可定制的可读流，可定制的可写流，以及定制的转换流，以及实现它们的内置接口

```js
var stream = require('stream')
var util = require('util')

function ReadStream() {
  stream.Readable.call(this)
}

util.inherits(ReadStream, stream.Readable)

// 只做一件事，push
ReadStream.prototype._read = function () {
  this.push('a')
  this.push('b')
  this.push('c \n')
  this.push('null')
}

function WritStream() {
  stream.Writable.call(this)
  this._cached = new Buffer('')
}

util.inherits(WritStream, stream.Writable)


// 只做一件事，打印
WritStream.prototype._write = function (chunk, encode, fn) {
  console.log(chunk.toString())
  fn()
}

function TransformStream() {
  stream.Transform.call(this)
}

// inherits 方法第一个参数是要继承目标的函数，第二个是被继承的
util.inherits(TransformStream, stream.Transform)

TransformStream.prototype._transform = function (chunk, encode, fn) {
  this.push(chunk)
  fn()
}

// flush 方法增加一些额外的内容
TransformStream.prototype._flush = function (fn) {
  this.push('我是新增的！')
  fn()
}

var rs = new ReadStream()
var ws = new WritStream()
var ts = new TransformStream()

re.pipe(ts).pipe(ws)
```
