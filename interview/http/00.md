

## cookie / csrf / xss

#### Cookie 机制（客户端）

因为 `HTTP` 协议是无状态的协议，一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接

这就意味着服务器无法从连接上跟踪会话，所以利用 `Cookie` 来确认用户的身份

`Cookie` 实际上是一小段的文本信息，客户端请求服务器，如果服务器需要记录该用户状态，就使用 `response` 向客户端浏览器颁发一个 `Cookie`，客户端浏览器会把 `Cookie` 保存起来

当浏览器再请求该网站时，浏览器把请求的网址连同该 `Cookie` 一同提交给服务器，服务器检查该 `Cookie`，以此来辨认用户状态，服务器还可以根据需要修改 `Cookie` 的内容

#### Session 机制（服务端）

除了使用 `Cookie`，`Web` 应用程序中还经常使用 `Session` 来记录客户端状态，`Session` 是服务器端使用的一种记录客户端状态的机制，使用上比 `Cookie` 简单一些，相应的也增加了服务器的存储压力

`Session` 是另一种记录客户状态的机制，不同的是 `Cookie` 保存在客户端浏览器中，而 `Session` 保存在服务器上

客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是 `Session`，客户端浏览器再次访问时只需要从该 `Session` 中查找该客户的状态就可以了

如果说 `Cookie` 机制是通过检查客户身上的 "通行证" 来确定客户身份的话，那么 `Session` 机制就是通过检查服务器上的 "客户明细表" 来确认客户身份，`Session` 相当于程序在服务器上建立的一份客户档案，客户来访的时候只需要查询客户档案表就可以了

> `Session` 对象是在客户端第一次请求服务器的时候创建的


#### XSS

全名是：`Cross-site scripting`，为了和 `CSS` 层叠样式表区分所以取名 `XSS`

`XSS` 其实就是 `Html` 的注入问题，攻击者的输入没有经过严格的控制进入了数据库，最终显示给来访的用户，导致可以在来访用户的浏览器里以浏览用户的身份执行 `Html` 代码，工作原理大致如下

`
攻击者发现 XSS 漏洞 —— 构造代码 —— 发送给受害人 —— 受害人打开 —— 攻击者获取受害人的 cookie —— 完成攻击
`

当用户的 `cookie` 被拿到以后，如果服务端 `session` 没有设置过期的话，以后甚至拿这个 `cookie` 而不需用户名密码，就可以以这个用户的身份登录成功了

但是 `XSS` 容易发现，因为攻击者需要登录后台完成攻击，管理员可以看日志发现攻击者


#### CSRF

全名是：`Cross-site request forgery`，中文名称：跨站请求伪造，与 `XSS` 非常不同，`XSS` 利用站点内的信任用户，而 `CSRF` 则通过伪装来自受信任用户的请求来利用受信任的网站

与 `XSS` 攻击相比，`CSRF` 攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比 `XSS` 更具危险性

可以这么理解 `CSRF` 攻击：攻击者盗用了你的身份，以你的名义发送恶意请求

要完成一次 `CSRF` 攻击，受害者必须依次完成两个步骤：

* 登录受信任网站 `A`，并在本地生成 `Cookie`

* 在不登出 `A` 的情况下，访问危险网站 `B`

`CSRF` 攻击是源于 `WEB` 的隐式身份验证机制，`WEB` 的身份验证机制虽然可以保证一个请求是来自于某个用户的浏览器，但却无法保证该请求是用户批准发送的

#### 防御

可以从服务端和客户端两方面着手，总的思想都是一致的，就是在客户端页面增加伪随机数，让钓鱼网站无法正常伪造请求














## SEO

#### META 标签

`META` 标签主要用于 `SEO` 优化，让搜索引擎能够发现你的页面，要让搜索引擎找到你，需要添加 `Keywords` 和 `description` 的 `meta` 标签

```html
<meta name="keywords" content="MP4, music, MP3"/>

<meta name="description" content="音乐,电影,视频"/>  
```

其他方法：

* 关键字隐藏在页面里，设定字体颜色跟背景一样

* 图片资源的 `alt` 属性里添加关键字（`<img src="..." alt="keywords">`）

* 在 `html` 注释中添加关键字


#### 正向代理与反向代理

**正向代理**

正向代理是位于客户端和原始服务器之间的服务器，为了能够从原始服务器获取请求的内容，客户端需要将请求发送给代理服务器

然后再由代理服务器将请求转发给原始服务器，原始服务器接受到代理服务器的请求并处理

最后将处理好的数据转发给代理服务器，之后再由代理服务器转发发给客户端，完成整个请求过程

![正向代理](http://images0.cnblogs.com/blog2015/456795/201507/051157002507977.jpg)

**反向代理**

反向代理方式是指代理原始服务器来接受来自 `Internet` 的链接请求，然后将请求转发给内部网络上的原始服务器，并将从原始服务器上得到的结果转发给 `Internet` 上请求数据的客户端

顾名思义，反向代理就是位于 `Internet` 和原始服务器之间的服务器，对于客户端来说就表现为一台服务器

客户端所发送的请求都是直接发送给反向代理服务器，然后由反向代理服务器统一调配

![反向代理](http://images0.cnblogs.com/blog2015/456795/201507/051215042498342.jpg)

**性能优化之反向代理**

和传统的代理服务器一样，反向代理服务器也有保护网站安全的作用，来自互联网的请求必须经过反向代理服务器，相当于在原始服务器之间增加一道屏障

除了安全功能，反向代理服务器也可以通过配置缓存功能加速 `web` 请求，当用户第一次访问静态内容的时候，静态内容就被缓存在反向代理服务器上，下一次用户请求静态资源时，直接从反向代理服务器返回静态内容，加速 `web` 请求访问速度，减轻原始服务器的压力

此外，反向代理服务器也可实现负载均衡的功能，而通过负载均衡构建应用集群可以提高系统的总处理能力，进而改善网站在高并发情况下的性能









## 网络协议的分层结构

#### 一. 协议的分层结构的概述

协议分层结构的思想是用一个模块的集合来完成不同的通信功能，以简化设计的复杂性，大多数的网络都按照层或级的方式来组织，每一层完成特定的功能，每一层都建立在它的下层之上

#### 二. 协议的分层结构的优点

1. 各层之间相互独立，复杂程度下降

2. 结构上可分隔开：各层都可以采用最合适的技术来实现

3. 易于实现和维护：系统已被分解为若干个相对独立的子系统

4. 灵活性好：一层发生变化其他各层不受影响

5. 能促进标准化工作：每一层的功能及所提供的服务都有精确的说明

#### 三. 协议的层次结构划分的原则

1. 每层的功能应是明确的，并且是相互独立的，当某一层的具体实现方法更新时，只要保持上､下层的接口不变，便不会对邻居产生影响

2. 层间接口必须清晰，跨越接口的信息量应尽可能少

3. 层数应适中｡若层数太少，则造成每一层的计算机网络协议太复杂;若层数太多，则体系结构过于复杂，使描述和实现各层功能变得困难




===========================================================

===========================================================






## http 协议

#### 特性

* 构建于 `TCP/IP` 协议之上，是一个应用层协议，默认端口号是 `80`

* 是无连接无状态的


#### GET

主要用于信息获取，而且应该是安全的和幂等的

* 所谓安全的意味着该操作用于获取信息而非修改信息，`GET` 请求一般不应产生副作用，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态

* 幂等的意味着对同一 `URL` 的多个请求应该返回同样的结果


#### POST

`http` 协议中规定 `post` 提交的数据必须在 `body` 部分中，但是协议中没有规定数据使用哪种编码方式或者数据格式（实际上，开发者完全可以自己决定消息主体的格式，只要最后发送的 `http` 请求满足上面的格式就可以）

但是，数据发送出去，还要服务端解析成功才有意义，一般服务端语言（及其框架），都内置了自动解析常见数据格式的功能

服务端通常是根据请求头（`headers`）中的 `Content-Type` 字段来获知请求中的消息主体是用何种方式编码，再对主体进行解析

所以说 `post` 提交数据方案，包含了 `Content-Type` 和消息主体编码方式两部分，用的比较多的方式有

* `application/x-www-form-urlencoded`，浏览器的原生 `<form>` 表单，如果不设置 `enctype` 属性，那么最终就会以 `application/x-www-form-urlencoded` 方式提交数据

* `multipart/form-data`，我们使用表单上传文件时，必须让 `<form>` 表单的 `enctype` 等于 `multipart/form-data`

看下面这个例子

```js
POST http://www.example.com HTTP/1.1
Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryrGKCBY7qhFd3TrwA

------WebKitFormBoundaryrGKCBY7qhFd3TrwA
Content-Disposition: form-data; name="text"

title
------WebKitFormBoundaryrGKCBY7qhFd3TrwA
Content-Disposition: form-data; name="file"; filename="chrome.png"
Content-Type: image/png

PNG ... content of chrome.png ...
------WebKitFormBoundaryrGKCBY7qhFd3TrwA--
```

* 首先生成了一个 `boundary` 用于分割不同的字段，为了避免与正文内容重复，`boundary` 很长很复杂

* 然后 `Content-Type` 里指明了数据是以 `multipart/form-data` 来编码，本次请求的 `boundary` 是什么内容

* 消息主体里按照字段个数又分为多个结构类似的部分，每部分都是以 `--boundary` 开始，紧接着是内容描述信息，然后是回车，最后是字段具体内容（文本或二进制）（如果传输的是文件，还要包含文件名和文件类型信息）

* 消息主体最后以 `--boundary--` 标示结束

关于 `multipart/form-data` 的详细定义，请前往 [rfc1867](https://www.ietf.org/rfc/rfc1867.txt) 查看（或者相对友好一点的 [MDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Disposition) 文档）（这种方式一般用来上传文件）

上面提到的这两种 `POST` 数据的方式，都是浏览器原生支持的，而且现阶段标准中原生 `<form>` 表单也只支持这两种方式（通过 `<form>` 元素的 `enctype` 属性指定，默认为 `application/x-www-form-urlencoded`，其实 `enctype` 还支持 `text/plain`，不过用得非常少）

我们完全可以定义自己的数据提交方式，例如 `application/json`，`text/xml`，乃至 `application/x-protobuf` 这种二进制格式，只要服务器可以根据 `Content-Type` 和 `Content-Encoding` 正确地解析出请求，都是没有问题的



#### 条件 GET

`http` 条件 GET 是 `http` 协议为了减少不必要的带宽浪费，提出的一种方案，详见 [RFC2616](https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html)

* 使用的时机？客户端之前已经访问过某网站，并打算再次访问该网站

* 使用的方法？客户端向服务器发送一个包询问是否在上一次访问网站的时间后是否更改了页面，如果服务器没有更新，显然不需要把整个网页传给客户端，客户端只要使用本地缓存即可，如果服务器对照客户端给出的时间已经更新了客户端请求的网页，则发送这个更新了的网页给用户

比如如下示例，客户端发送请求如下

```js
GET / HTTP/1.1
Host: www.sina.com.cn:80
If-Modified-Since:Thu, 4 Feb 2010 20:39:13 GMT
Connection: Close
```

第一次请求时，服务器端返回请求数据，之后的请求服务器会根据请求中的 `If-Modified-Since` 字段判断响应文件没有更新

如果没有更新，服务器返回一个 `304 Not Modified` 响应，告诉浏览器请求的资源在浏览器上没有更新，可以使用已缓存的上次获取的文件

```js
HTTP/1.0 304 Not Modified  
Date: Thu, 04 Feb 2010 12:38:41 GMT  
Content-Type: text/html  
Expires: Thu, 04 Feb 2010 12:39:41 GMT  
Last-Modified: Thu, 04 Feb 2010 12:29:04 GMT  
Age: 28  
X-Cache: HIT from sy32-21.sina.com.cn  
Connection: close 
```
 
如果服务器端资源已经更新的话，就返回正常的响应



#### 持久连接

我们知道 `http` 协议采用请求应答模式

* 当使用普通模式，即非 `Keep-Alive` 模式时，每个请求或应答客户和服务器都要新建一个连接，完成之后立即断开连接（`http` 协议为无连接的协议）

* 当使用 `Keep-Alive` 模式（又称持久连接、连接重用）时，`Keep-Alive` 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，`Keep-Alive` 功能避免了建立或者重新建立连接

在 `http 1.0` 版本中，并没有官方的标准来规定 `Keep-Alive` 如何工作，因此实际上它是被附加到 `http 1.0` 协议上

如果客户端浏览器支持 `Keep-Alive` ，那么就在`http`请求头中添加一个字段 `Connection: Keep-Alive`，当服务器收到附带有 `Connection: Keep-Alive` 的请求时，它也会在响应头中添加一个同样的字段来使用 `Keep-Alive` ，这样一来，客户端和服务器之间的`http`连接就会被保持，不会断开（超过 `Keep-Alive` 规定的时间，意外断电等情况除外），当客户端发送另外一个请求时，就使用这条已经建立的连接

在 `http 1.1` 版本中，默认情况下所有连接都被保持，如果加入 `Connection: close` 才关闭，目前大部分浏览器都使用 `http 1.1` 协议，也就是说默认都会发起 `Keep-Alive` 的连接请求了，所以是否能完成一个完整的 `Keep-Alive` 连接就看服务器设置情况

由于 `http 1.0` 没有官方的 `Keep-Alive` 规范，并且也已经基本被淘汰，以下讨论均是针对 `http 1.1` 标准中的 `Keep-Alive` 展开的

有几个需要注意的地方

* `Keep-Alive` 简单说就是保持当前的 `TCP` 连接，避免了重新建立连接

* 长连接不可能一直保持，例如 `Keep-Alive: timeout=5, max=100` 表示这个 `TCP` 通道可以保持 `5` 秒，`max=100`，表示这个长连接最多接收 `100` 次请求就断开

* 是一个无状态协议，这意味着每个请求都是独立的，`Keep-Alive` 没能改变这个结果，另外 `Keep-Alive` 也不能保证客户端和服务器之间的连接一定是活跃的，在 `http 1.1` 版本中也如此，唯一能保证的就是当连接被关闭时你能得到一个通知，所以不应该让程序依赖于 `Keep-Alive` 的保持连接特性，否则会有意想不到的后果

使用长连接之后，客户端、服务端怎么知道本次传输结束呢？主要是两部分

* 判断传输数据是否达到了 `Content-Length` 指示的大小

* 动态生成的文件没有 `Content-Length`，它是分块传输（`chunked`），这时候就要根据 `chunked` 编码来判断，`chunked` 编码的数据在最后有一个空 `chunked` 块，表明本次传输数据结束，详见 [Keep-Alive 模式](https://www.cnblogs.com/skynet/archive/2010/12/11/1903347.html)




#### Transfer-Encoding（chunked 分块传输）

`Transfer-Encoding` 是一个用来标示 `HTTP` 报文传输格式的头部值，当前的 `http` 规范里实际上只定义了一种传输取值 `chunked`

如果一个 `http` 消息（请求消息或应答消息）的 `Transfer-Encoding` 消息头的值为 `chunked`，那么消息体由数量未定的块组成，并以最后一个大小为 `0` 的块为结束

每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个 `CRLF`（回车及换行），然后是数据本身，最后块 `CRLF` 结束，在一些实现中块大小和 `CRLF` 之间填充有白空格（`0x20`）

最后一块是单行，由块大小（`0`），一些可选的填充白空格，以及 `CRLF`，最后一块不再包含任何数据，但是可以发送可选的尾部，包括消息头字段，消息最后以 `CRLF` 结尾

一个示例响应如下：

```js
HTTP/1.1 200 OK
Content-Type: text/plain
Transfer-Encoding: chunked

25
This is the data in the first chunk

1A
and this is the second one
0
```

* `chunked` 和 `multipart` 两个名词在意义上有类似的地方，不过在 `http` 协议当中这两个概念则不是一个类别的，`multipart` 是一种 `Content-Type`，标示 `http` 报文内容的类型，而 `chunked` 是一种传输格式，标示报头将以何种方式进行传输，

* `chunked` 传输不能事先知道内容的长度，只能靠最后的空 chunk 块来判断，因此对于下载请求来说，是没有办法实现进度的，在浏览器和下载工具中，偶尔我们也会看到有些文件是看不到下载进度的，即采用 `chunked` 方式进行下载，

* `chunked` 的优势在于，服务器端可以边生成内容边发送，无需事先生成全部的内容，`http/2` 不支持 `Transfer-Encoding: chunked`，因为 `http/2` 有自己的 `streaming` 传输方式（[Transfer-Encoding](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding)）



#### HTTP Pipelining（HTTP 管线化）

默认情况下 `http` 协议中每个传输层连接只能承载一个 `http` 请求和响应，浏览器会在收到上一个请求的响应之后，再发送下一个请求，在使用持久连接的情况下，某个连接上消息的传递类似于

```js
请求1 ==> 响应1 ==> 请求2 ==> 响应2 ==> 请求3 ==> 响应3
```

`http Pipelining`（管线化）是将多个 `http` 请求整批提交的技术，在传送过程中不需等待服务端的回应，使用 `http Pipelining` 技术之后，某个连接上的消息变成了类似于

```js
请求1 ==> 请求2 ==> 请求3 ==> 响应1 ==> 响应2 ==> 响应3
```

注意下面几点：

* 管线化机制通过持久连接（persistent connection）完成，仅 `http/1.1` 支持此技术（`http/1.0` 不支持）

* 只有 `GET` 和 `HEAD` 请求可以进行管线化，而 `POST` 则有所限制

* 初次创建连接时不应启动管线机制，因为对方（服务器）不一定支持 `http/1.1` 版本的协议

* 管线化不会影响响应到来的顺序，如上面的例子所示，响应返回的顺序并未改变

* `http /1.1` 要求服务器端支持管线化，但并不要求服务器端也对响应进行管线化处理，只是要求对于管线化的请求不失败即可

由于上面提到的服务器端问题，开启管线化很可能并不会带来大幅度的性能提升，而且很多服务器端和代理程序对管线化的支持并不好，因此现代浏览器如 `Chrome` 和 `Firefox` 默认并未开启管线化支持

更多关于 `http Pipelining` 的知识可以参考 [Connection management in HTTP/1.x](https://developer.mozilla.org/en-US/docs/Web/HTTP/Connection_management_in_HTTP_1.x)



#### 会话跟踪

* 什么是会话？客户端打开与服务器的连接发出请求到服务器响应客户端请求的全过程称之为会话

* 什么是会话跟踪？会话跟踪指的是对同一个用户对服务器的连续的请求和接受响应的监视

* 为什么需要会话跟踪？浏览器与服务器之间的通信是通过 `http` 协议进行通信的，而 `http` 协议是无状态的协议，它不能保存客户的信息，即一次响应完成之后连接就断开了，下一次的请求需要重新连接，这样就需要判断是否是同一个用户，所以才有会话跟踪技术来实现这种要求

会话跟踪常用的方法:

* `URL` 重写

`URL`（统一资源定位符）是 `Web` 上特定页面的地址，`URL` 重写的技术就是在 `URL` 结尾添加一个附加数据以标识该会话，把会话 `id` 通过 `URL` 的信息传递过去，以便在服务器端进行识别不同的用户

* 隐藏表单域

将会话 `id` 添加到 `HTML` 表单元素中提交到服务器，此表单元素并不在客户端显示

* `Cookie`

`Cookie` 是 `Web` 服务器发送给客户端的一小段信息，客户端请求时可以读取该信息发送到服务器端，进而进行用户的识别，对于客户端的每次请求，服务器都会将 `Cookie` 发送到客户端，在客户端可以进行保存，以便下次使用

客户端可以采用两种方式来保存这个 `Cookie` 对象，一种方式是保存在客户端内存中，称为临时 `Cookie`，浏览器关闭后这个 `Cookie` 对象将消失，另外一种方式是保存在客户机的磁盘上，称为永久 `Cookie`，以后客户端只要访问该网站，就会将这个 `Cookie` 再次发送到服务器上，前提是这个 `Cookie` 在有效期内，这样就实现了对客户的跟踪（`Cookie` 是可以被客户端禁用的）

* `Session`

每一个用户都有一个不同的 `Session`，各个用户之间是不能共享的，是每个用户所独享的，在 `Session` 中可以存放信息

在服务器端会创建一个 `Session` 对象，产生一个 `sessionID` 来标识这个 `Session` 对象，然后将这个 `sessionID` 放入到 `Cookie` 中发送到客户端，下一次访问时 `sessionID` 会发送到服务器，在服务器端进行识别不同的用户

`Session` 的实现依赖于 `Cookie`，如果 `Cookie` 被禁用，那么 `session` 也将失效





#### CSRF（Cross-site request forgery，跨站请求伪造）

全称为 `Cross-site request forgery`，跨站请求伪造

`CSRF`（`XSRF`） 顾名思义是伪造请求，冒充用户在站内的正常操作

如何防范 `CSRF` 攻击？可以注意以下几点：

* 关键操作只接受 `POST` 请求

* 验证码

`CSRF` 攻击的过程，往往是在用户不知情的情况下构造网络请求，所以如果使用验证码，那么每次操作都需要用户进行互动，从而简单有效的防御了 `CSRF` 攻击

但是如果你在一个网站作出任何举动都要输入验证码会严重影响用户体验，所以验证码一般只出现在特殊操作里面，或者在注册时候使用

* 检测 `Referer`

常见的互联网页面与页面之间是存在联系的，比如你在论坛留言，那么不管你留言后重定向到哪里去了，之前的那个网址一定会包含留言的输入框，这个之前的网址就会保留在新页面头文件的 `Referer` 中

通过检查 `Referer` 的值，我们就可以判断这个请求是合法的还是非法的，但是问题出在服务器不是任何时候都能接受到 `Referer` 的值，所以 `Referer Check` 一般用于监控 `CSRF` 攻击的发生，而不用来抵御攻击

* `Token`

目前主流的做法是使用 `Token` 抵御 `CSRF` 攻击，下面通过分析 `CSRF` 攻击来理解为什么 `Token` 能够有效

`CSRF` 攻击要成功的条件在于攻击者能够预测所有的参数从而构造出合法的请求，所以根据不可预测性原则，我们可以对参数进行加密从而防止 `CSRF` 攻击

另一个更通用的做法是保持原有参数不变，另外添加一个参数 `Token`，其值是随机的，这样攻击者因为不知道 `Token` 而无法构造出合法的请求进行攻击

`Token` 使用原则


  * `Token` 要足够随机 -- 只有这样才算不可预测

  * `Token` 是一次性的，即每次请求成功后要更新 `Token` -- 这样可以增加攻击难度，增加预测难度

  * `Token` 要注意保密性 -- 敏感操作使用 `POST`，防止 `Token` 出现在 `URL` 中

注意：过滤用户输入的内容不能阻挡 `CSRF`，我们需要做的是过滤请求的来源



#### XSS（Cross Site Scripting，跨站脚本攻击）

`XSS` 是注入攻击的一种，其特点是不对服务器端造成任何伤害，而是通过一些正常的站内交互途径，例如发布评论，提交含有 `JavaScript` 的内容文本，这时服务器端如果没有过滤或转义掉这些脚本，作为内容发布到了页面上，其他用户访问这个页面的时候就会运行这些脚本（比如运行一些盗号或者其他未授权的操作）

`XSS` 是实现 `CSRF` 的诸多途径中的一条，但绝对不是唯一的一条，一般习惯上把通过 `XSS` 来实现的 `CSRF` 称为 `XSRF`

如何防御 `XSS` 攻击？

理论上，所有可输入的地方没有对输入数据进行处理的话，都会存在 `XSS` 漏洞，漏洞的危害取决于攻击代码的威力，攻击代码也不局限于 `script`，防御 `XSS` 攻击最简单直接的方法，就是过滤用户的输入

当我们需要用户输入 `HTML` 的时候，需要对用户输入的内容做更加小心细致的处理，仅仅粗暴地去掉 `script` 标签是没有用的，任何一个合法 `HTML` 标签都可以添加 `onclick` 一类的事件属性来执行 `JavaScript`

更好的方法可能是，将用户的输入使用 `HTML` 解析库进行解析，获取其中的数据，然后根据用户原有的标签属性，重新构建 `HTML` 元素树，构建的过程中，所有的标签、属性都只从白名单中拿取







## https

`https` 即 `http over TLS`，是一种在加密信道进行 `http` 内容传输的协议

> `TLS` 的早期版本叫做 `SSL`，`SSL` 的 `1.0`，`2.0`，`3.0` 版本均已经被废弃，出于安全问题考虑广大浏览器也不再对老旧的 `SSL` 版本进行支持了，因此这里我们就统一使用 `TLS` 名称了

`TLS` 的基本过程如下（详细可见 [what-happens-when](https://github.com/skyline75489/what-happens-when-zh_CN#tls)）

* 客户端发送一个 `ClientHello` 消息到服务器端，消息中同时包含了它的 `Transport Layer Security`（`TLS`） 版本，可用的加密算法和压缩算法
* 服务器端向客户端返回一个 `ServerHello` 消息，消息中包含了服务器端的 `TLS` 版本，服务器所选择的加密和压缩算法，以及数字证书认证机构（`Certificate Authority`，缩写 `CA`）签发的服务器公开证书，证书中包含了公钥，客户端会使用这个公钥加密接下来的握手过程，直到协商生成一个新的对称密钥
* 客户端根据自己的信任 `CA` 列表，验证服务器端的证书是否可信，如果认为可信，客户端会生成一串伪随机数，使用服务器的公钥加密它，这串随机数会被用于生成新的对称密钥
* 服务器端使用自己的私钥解密上面提到的随机数，然后使用这串随机数生成自己的对称主密钥
* 客户端发送一个 `Finished` 消息给服务器端，使用对称密钥加密这次通讯的一个散列值
* 服务器端生成自己的 `hash` 值，然后解密客户端发送来的信息，检查这两个值是否对应，如果对应，就向客户端发送一个 `Finished` 消息，也使用协商好的对称密钥加密
* 从现在开始，接下来整个 `TLS` 会话都使用对称秘钥进行加密，传输应用层（`http`）内容

从上面的过程可以看到，`TLS` 的完整过程需要三个算法（协议），密钥交互算法，对称加密算法，和消息认证算法（`TLS` 的传输会使用 `MAC`（`message authentication code`） 进行完整性检查）

我们以 `Github` 网站使用的 `TLS` 为例

* 使用浏览器可以看到它使用的加密为 `TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256`

* 其中密钥交互算法是 `ECDHE_RSA`

* 对称加密算法是 `AES_128_GCM`

* 消息认证（`MAC`）算法为 `SHA256`




#### TLS 证书机制

`https` 过程中很重要的一个步骤，是服务器需要有 `CA` 颁发的证书，客户端根据自己的信任 `CA` 列表验证服务器的身份，现代浏览器中，证书验证的过程依赖于证书信任链

所谓证书信任链，即一个证书要依靠上一级证书来证明自己是可信的，最顶层的证书被称为根证书，拥有根证书的机构被称为根 `CA`

还是以 `Github` 为例，在浏览器中我们可以看到它的证书信任链如下

```js
DigiCert High Assurance EV Root CA ==> DigiCert SHA2 Extended Validation Server CA ==> Github.com
```

从上到下即 `Root CA` ==> 二级 `CA` ==> 网站

前面提到，证书当中包括 `CN`（`Common Name`），浏览器在验证证书的同时，也会验证 `CN` 的正确性，即不光需要验证这是一个合法的证书，还需要验证这是一个用于 `Github.com` 的证书，

既然所有的信任，最终要落到根 `CA` 上，根证书本身又是怎么获得的呢？答案也很简单，根证书一般是操作系统自带的，不管是桌面系统 `Windows`，`macOS` 还是移动端系统 `Android`, `iOS` 都会内置一系列根证书，随着操作系统本身的升级，根证书也会随着升级进行更新

对浏览器而已，浏览器当然也有选择信任某个根证书的权利，`Chrome` 浏览器一般是跟随系统根证书信任的，`Firefox` 浏览器通常是使用自带的一套证书信任机制，不受系统证书的影响

在使用 `curl` 等工具时，我们还可以自行选择证书进行信任

有权威的信任，最终都要落到一个单点信任，不管是 `Root CA`，还是微软，苹果，谷歌等操作系统厂商



#### 中间人攻击

`https` 的过程并不是密不透风的，`https` 有若干漏洞，给中间人攻击（`Man In The Middle Attack`，简称 `MITM`）提供了可能

所谓中间人攻击，指攻击者与通讯的两端分别建立独立的联系，并交换其所收到的数据，使通讯的两端认为他们正在通过一个私密的连接与对方直接对话，但事实上整个会话都被攻击者完全控制，在中间人攻击中，攻击者可以拦截通讯双方的通话并插入新的内容

#### SSL 剥离

`SSL` 剥离即阻止用户使用 `https` 访问网站，由于并不是所有网站都只支持 `https`，大部分网站会同时支持 `http` 和 `https` 两种协议，用户在访问网站时，也可能会在地址栏中输入 `http://` 的地址，第一次的访问完全是明文的，这就给了攻击者可乘之机，通过攻击 `DNS` 响应，攻击者可以将自己变成中间人

`DNS` 作为基于 `UDP` 的协议是相当不安全的，为了保证 `DNS` 的安全可以使用 `DNS over TCP` 等机制，可以参考 [浅析 DNS-over-TLS](https://zhuanlan.zhihu.com/p/47170371)

#### HSTS

为了防止上面说的这种情况，一种叫做 `HSTS` 的技术被引入了，`HSTS`（`HTTP Strict Transport Security`）是用于强制浏览器使用 `https` 访问网站的一种机制，它的基本机制是在服务器返回的响应中，加上一个特殊的头部，指示浏览器对于此网站，强制使用 `https` 进行访问

```js
Strict-Transport-Security: max-age=31536000; includeSubdomains; preload
```

可以看到如果这个过期时间非常长，就是导致在很长一段时间内，浏览器都会强制使用 `https` 访问该网站

`HSTS` 有一个很明显的缺点，是需要等待第一个服务器的影响中的头部才能生效，但如果第一次访问该网站就被攻击呢？

为了解决这个问题，浏览器中会带上一些网站的域名，被称为 `HSTS preload list`，对于在这个 `list` 的网站来说，直接强制使用 `https`

#### 伪造证书攻击

`HSTS` 只解决了 `SSL` 剥离的问题，然而即使在全程使用 `https` 的情况下，我们仍然有可能被监听

假设我们想访问 `www.google.com`，但我们的 `DNS` 服务器被攻击了，指向的 `IP` 地址并非 `Google` 的服务器，而是攻击者的 `IP`，当攻击者的服务器也有合法的证书的时候，我们的浏览器就会认为对方是 `Google` 服务器，从而信任对方，这样，攻击者便可以监听我们和谷歌之前的所有通信了

可以看到攻击者有两步需要操作，第一步是需要攻击 `DNS` 服务器，第二步是攻击者自己的证书需要被用户信任，这一步对于用户来说是很难控制的，需要证书颁发机构能够控制自己不滥发证书


#### HPKP

`HPKP` 技术是为了解决伪造证书攻击而诞生的

`HPKP`（`Public Key Pinning Extension for HTTP`）在 `HSTS` 上更进一步，`HPKP` 直接在返回头中存储服务器的公钥指纹信息，一旦发现指纹和实际接受到的公钥有差异，浏览器就可以认为正在被攻击：

```js
Public-Key-Pins: pin-sha256="base64=="; max-age=expireTime [; includeSubDomains][; report-uri="reportURI"]
```

和 `HSTS` 类似，`HPKP` 也依赖于服务器的头部返回，不能解决第一次访问的问题，浏览器本身也会内置一些 `HPKP` 列表

> `HPKP` 技术仍然不能阻止第一次访问的攻击问题，部署和配置 `HPKP` 相当繁琐，一旦网站配置错误，就会导致网站证书验证失败，且在过期时间内无法有效恢复，`HPKP` 的机制也引来了一些安全性问题，`Chrome 67` 中废除了对 `HPKP` 的支持，在 `Chrome 72` 中 `HPKP` 被彻底移除







## TCP/IP

`TCP/IP` 协议是一个协议簇，里面包括很多协议的，`UDP` 只是其中的一个， 之所以命名为 `TCP/IP` 协议，因为 `TCP`、`IP` 协议是两个很重要的协议，就用他两命名了

`TCP/IP` 协议集包括应用层,传输层，网络层，网络访问层

## TCP

* `TCP` 提供一种面向连接的、可靠的字节流服务

* 在一个 `TCP` 连接中，仅有两方进行彼此通信，广播和多播不能用于 `TCP`

* `TCP` 使用校验和，确认和重传机制来保证可靠传输

* `TCP` 给数据分节进行排序，并使用累积确认保证数据的顺序不变和非重复

* `TCP` 使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制

注意：`TCP` 并不能保证数据一定会被对方接收到，因为这是不可能的，`TCP` 能够做到的是，如果有可能，就把数据递送到接收方，否则就（通过放弃重传并且中断连接这一手段）通知用户，因此准确说 `TCP` 也不是 `100% `可靠的协议，它所能提供的是数据的可靠递送或故障的可靠通知



#### 三次握手与四次挥手

所谓三次握手（`Three-way Handshake`），是指建立一个 `TCP` 连接时，需要客户端和服务器总共发送三个包

三次握手的目的是连接服务器指定端口，建立 `TCP` 连接，并同步连接双方的序列号和确认号，交换 `TCP` 窗口大小信息，在 `socket` 编程中，客户端执行 `connect()` 时，将触发三次握手

* 第一次握手（`SYN = 1`，`seq =x`）

客户端发送一个 `TCP` 的 `SYN` 标志位置 `1` 的包，指明客户端打算连接的服务器的端口，以及初始序号 `x`，存在包头的序列号（`Sequence Number`）字段里

发送完毕后，客户端进入 `SYN_SEND` 状态

* 第二次握手（`SYN = 1`，`ACK = 1`，`seq = y`，`ACKnum = x + 1`）

服务器发回确认包（`ACK`）应答，即 `SYN` 标志位和 `ACK` 标志位均为 `1`，服务器端选择自己 `ISN` 序列号，放到 `Seq` 域里，同时将确认序号（`Acknowledgement Number`）设置为客户的 `ISN` 加 `1`，即 `x + 1`， 发送完毕后，服务器端进入 `SYN_RCVD` 状态

* 第三次握手（`ACK = 1`，`ACKnum = y + 1`）

客户端再次发送确认包（`ACK`），`SYN` 标志位为 `0`，`ACK` 标志位为 `1`，并且把服务器发来 `ACK` 的序号字段 `+ 1`，放在确定字段中发送给对方，并且在数据段放写 `ISN` 的 `+ 1`

发送完毕后，客户端进入 `ESTABLISHED` 状态，当服务器端接收到这个包时，也进入 `ESTABLISHED` 状态，`TCP` 握手结束

三次握手的过程的示意图如下

![](./01.png)


`TCP` 的连接的拆除需要发送四个包，因此称为四次挥手（`Four-way handshake`），也叫做改进的三次握手，客户端或服务器均可主动发起挥手动作，在 `socket` 编程中，任何一方执行 `close()` 操作即可产生挥手操作，

* 第一次挥手（`FIN = 1`，`seq = x`）

假设客户端想要关闭连接，客户端发送一个 `FIN` 标志位置为 `1` 的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据

发送完毕后，客户端进入 `FIN_WAIT_1` 状态

* 第二次挥手（`ACK = 1`，`ACKnum = x + 1`）

服务器端确认客户端的 `FIN` 包，发送一个确认包，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接

发送完毕后，服务器端进入 `CLOSE_WAIT` 状态，客户端接收到这个确认包之后，进入 `FIN_WAIT_2` 状态，等待服务器端关闭连接

* 第三次挥手（`FIN = 1`，`seq = y`）

服务器端准备好关闭连接时，向客户端发送结束连接请求，`FIN` 置为 `1`

发送完毕后，服务器端进入 `LAST_ACK` 状态，等待来自客户端的最后一个 `ACK`

* 第四次挥手（`ACK = 1`，`ACKnum = y + 1`）

客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入 `TIME_WAIT` 状态，等待可能出现的要求重传的 `ACK` 包

服务器端接收到这个确认包之后，关闭连接，进入 `CLOSED` 状态

客户端等待了某个固定时间（`2MSL（2 Maximum Segment Lifetime）`，两个最大段生命周期）之后，没有收到服务器端的 `ACK` ，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入 CLOSED 状态

四次挥手的示意图如下：

![](./02.png)




#### SYN 攻击

* 什么是 `SYN` 攻击（`SYN Flood`）？

在三次握手过程中，服务器发送 `SYN-ACK` 之后，收到客户端的 `ACK` 之前的 `TCP` 连接称为半连接（`half-open connect`），此时服务器处于 `SYN_RCVD` 状态，当收到 `ACK` 后，服务器才能转入 `ESTABLISHED` 状态

`SYN` 攻击指的是，攻击客户端在短时间内伪造大量不存在的 `IP` 地址，向服务器不断地发送 `SYN` 包，服务器回复确认包，并等待客户的确认，由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的 `SYN` 包将长时间占用未连接队列，正常的 `SYN` 请求被丢弃，导致目标系统运行缓慢，严重者会引起网络堵塞甚至系统瘫痪

`SYN` 攻击是一种典型的 `DoS/DDoS` 攻击

* 如何检测 `SYN` 攻击？

检测 `SYN` 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源 `IP` 地址是随机的，基本上可以断定这是一次 `SYN` 攻击，在 `Linux/Unix` 上可以使用系统自带的 `netstats` 命令来检测 `SYN` 攻击

* 如何防御 `SYN` 攻击？

`SYN` 攻击不能完全被阻止，除非将 `TCP` 协议重新设计，我们所做的是尽可能的减轻 `SYN` 攻击的危害，常见的防御 `SYN` 攻击的方法有如下几种

  * 缩短超时（`SYN Timeout`）时间

  * 增加最大半连接数

  * 过滤网关防护

  * `SYN Cookies` 技术



#### TCP KeepAlive

`TCP` 的连接，实际上是一种纯软件层面的概念，在物理层面并没有连接这种概念

`TCP` 通信双方建立交互的连接，但是并不是一直存在数据交互，有些连接会在数据交互完毕后，主动释放连接，而有些不会，在长时间无数据交互的时间段内，交互双方都有可能出现掉电、死机、异常重启等各种意外

当这些意外发生之后，这些 `TCP` 连接并未来得及正常释放，在软件层面上，连接的另一方并不知道对端的情况，它会一直维护这个连接，长时间的积累会导致非常多的半打开连接，造成端系统资源的消耗和浪费，为了解决这个问题，在传输层可以利用 `TCP` 的 `KeepAlive` 机制实现来实现，主流的操作系统基本都在内核里支持了这个特性

`TCP KeepAlive` 的基本原理是，隔一段时间给连接对端发送一个探测包，如果收到对方回应的 `ACK`，则认为连接还是存活的，在超过一定重试次数之后还是没有收到对方的回应，则丢弃该 `TCP` 连接

更多详细可以参考 [TCP-Keepalive-HOWTO](http://www.tldp.org/HOWTO/html_single/TCP-Keepalive-HOWTO/)

这里主要说一下，`TCP KeepAlive` 的局限，首先 `TCP KeepAlive` 监测的方式是发送一个 `probe` 包，会给网络带来额外的流量，另外 `TCP KeepAlive` 只能在内核层级监测连接的存活与否，而连接的存活不一定代表服务的可用，例如当一个服务器 `CPU` 进程服务器占用达到 `100%`，已经卡死不能响应请求了

此时 `TCP KeepAlive` 依然会认为连接是存活的，因此 `TCP KeepAlive` 对于应用层程序的价值是相对较小的，需要做连接保活的应用层程序，例如 `QQ`，往往会在应用层实现自己的心跳功能


## UDP

`UDP` 是一个简单的传输层协议，和 `TCP` 相比，`UDP` 有下面几个显著特性

* `UDP` 缺乏可靠性，`UDP` 本身不提供确认，序列号，超时重传等机制，`UDP` 数据报可能在网络中被复制，被重新排序，即 `UDP` 不保证数据报会到达其最终目的地，也不保证各个数据报的先后顺序，也不保证每个数据报只到达一次

* `UDP` 数据报是有长度的，每个 `UDP` 数据报都有长度，如果一个数据报正确地到达目的地，那么该数据报的长度将随数据一起传递给接收方，而 `TCP` 是一个字节流协议，没有任何（协议上的）记录边界，

* `UDP` 是无连接的，`UDP` 客户和服务器之前不必存在长期的关系，`UDP` 发送数据报之前也不需要经过握手创建连接的过程

* `UDP` 支持多播和广播




